{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**UXO Classification using RESNET18:**\n",
        "\n",
        "This notebook serves to outline the code used in developing a classification model using RESNET18. The classification is performed on sonar data, positive entailing to unexploded ordnances (UXOs) underwater and negative from numerous common objects found also underwater. The full project can be accessed on this github repository: https://github.com/MansourSaliba/UXO_detection_model"
      ],
      "metadata": {
        "id": "8FoM-FxTjyt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Initial steps:***"
      ],
      "metadata": {
        "id": "M8Ptk1vOlWRn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-62fGlyjrkR"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "# Install packages before this step if not installed (e.g. !pip install ultralytics mlflow)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "kS29JEL6kkxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths (change based on your specific path)\n",
        "\n",
        "MLFLOW_TRACKING_URI = '/content/drive/MyDrive/UXO_project/mlruns'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/UXO_project/models/resnet18_uxo.pt'\n",
        "UXO_PATH = '/content/drive/MyDrive/UXO_project/UXO_dataset/processed/UXO/aris_polar_standardized'\n",
        "NON_UXO_PATH = '/content/drive/MyDrive/UXO_project/UXO_dataset/processed/Negative'\n"
      ],
      "metadata": {
        "id": "VPsg084vkypU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MLflow (to track metrics)\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(\"UXO_Classification\")"
      ],
      "metadata": {
        "id": "lj_Bx3DTlF7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check runtime\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "cmgxfAR7mHo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preparing dataset:***"
      ],
      "metadata": {
        "id": "0pBcA2vPlchW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UXODataset(Dataset):\n",
        "    def __init__(self, uxo_files, non_uxo_files, transform=None):\n",
        "        self.file_paths = uxo_files + non_uxo_files\n",
        "        self.labels = [1]*len(uxo_files) + [0]*len(non_uxo_files)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.file_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Get all files\n",
        "uxo_files = [os.path.join(UXO_PATH, f) for f in os.listdir(UXO_PATH) if f.endswith('.png')]\n",
        "non_uxo_files = [os.path.join(NON_UXO_PATH, f) for f in os.listdir(NON_UXO_PATH) if f.endswith('.png')]"
      ],
      "metadata": {
        "id": "FalcvX0XlPef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Noticed an imbalance between positive and negative data so implemented the below steps\n",
        "\n",
        "# Step 1: Mild subsampling (reduce UXO from 2,573 to 2,200, keeping most data)\n",
        "uxo_files = uxo_files[:2200]  # Now 2,200 vs 1,868 (15% → 8.2% imbalance)\n",
        "\n",
        "# Step 2: Add class weights\n",
        "uxo_weight = len(non_uxo_files) / (len(uxo_files) + len(non_uxo_files))\n",
        "non_uxo_weight = len(uxo_files) / (len(uxo_files) + len(non_uxo_files))\n",
        "criterion = nn.BCEWithLogitsLoss(\n",
        "    pos_weight=torch.tensor([non_uxo_weight / uxo_weight], device=device)\n",
        ")\n",
        "\n",
        "# Step 3: Slightly augment Non-UXO\n",
        "train_transform_non_uxo = transforms.Compose([\n",
        "    transforms.Resize(TARGET_SIZE),\n",
        "    transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Verify balanced classes\n",
        "assert abs(len(uxo_files) - len(non_uxo_files)) / (len(uxo_files) + len(non_uxo_files)) < 0.1, \"Class imbalance >10%\""
      ],
      "metadata": {
        "id": "iarT4tcLl8_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "\n",
        "TARGET_SIZE = (224, 414) # Maintaining aspect ratio (original 1636×3025 → scaled to 224×414)\n",
        "\n",
        "# Augmentations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(TARGET_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(TARGET_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Get ALL files and labels first\n",
        "all_files = np.array(uxo_files + non_uxo_files)\n",
        "all_labels = np.array([1]*len(uxo_files) + [0]*len(non_uxo_files))\n",
        "\n",
        "# 80/10/10 stratified split\n",
        "train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
        "    all_files, all_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=all_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_files, test_files, val_labels, test_labels = train_test_split(\n",
        "    temp_files, temp_labels,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Verify\n",
        "assert len(set(val_files) & set(test_files)) == 0\n",
        "print(f\"Final counts - Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")"
      ],
      "metadata": {
        "id": "mKMWYZR_nPPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = UXODataset(\n",
        "    [f for f, l in zip(train_files, train_labels) if l == 1],\n",
        "    [f for f, l in zip(train_files, train_labels) if l == 0],\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = UXODataset(\n",
        "    [f for f, l in zip(val_files, val_labels) if l == 1],\n",
        "    [f for f, l in zip(val_files, val_labels) if l == 0],\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "test_dataset = UXODataset(\n",
        "    [f for f, l in zip(test_files, test_labels) if l == 1],\n",
        "    [f for f, l in zip(test_files, test_labels) if l == 0],\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "# DataLoaders\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "_Z-cwTp5nvRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Setting up the model:***"
      ],
      "metadata": {
        "id": "_l91u1Pxn0KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)"
      ],
      "metadata": {
        "id": "V0VPMHB7n4Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Training loop:***"
      ],
      "metadata": {
        "id": "0PFPj8ProBOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop with Early Stopping\n",
        "\n",
        "def train_model():\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        # Log parameters\n",
        "        mlflow.log_params({\n",
        "            \"model\": \"ResNet18\",\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"optimizer\": \"Adam\",\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"weight_decay\": 1e-4,\n",
        "            \"scheduler\": \"ReduceLROnPlateau\",\n",
        "            \"dropout\": 0.3,\n",
        "            \"target_size\": TARGET_SIZE\n",
        "        })\n",
        "\n",
        "        for epoch in range(50):  # Max epochs\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            # Training phase\n",
        "            for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "                inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_acc = 100 * correct / total\n",
        "            avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "            # Validation phase\n",
        "            val_loss, val_acc = evaluate(model, val_loader)\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Log metrics\n",
        "            mlflow.log_metrics({\n",
        "                \"train_loss\": avg_train_loss,\n",
        "                \"train_acc\": train_acc,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_acc\": val_acc,\n",
        "                \"lr\": optimizer.param_groups[0]['lr']\n",
        "            }, step=epoch)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: \"\n",
        "                  f\"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.2f}% | \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "                mlflow.log_artifact(MODEL_SAVE_PATH)\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return loss / len(loader), 100 * correct / total\n",
        "\n",
        "# Start training\n",
        "train_model()\n"
      ],
      "metadata": {
        "id": "ndMeLx0noEFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Set Evaluation\n",
        "\n",
        "def test_model():\n",
        "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    test_loss, test_acc = evaluate(model, test_loader)\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Test_Evaluation\"):\n",
        "        mlflow.log_metrics({\n",
        "            \"test_loss\": test_loss,\n",
        "            \"test_acc\": test_acc\n",
        "        })\n",
        "\n",
        "        # Log confusion matrix\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs)\n",
        "                preds = (outputs > 0.5).float().cpu()\n",
        "                all_preds.extend(preds.numpy())\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.xticks([0, 1], ['Non-UXO', 'UXO'])\n",
        "        plt.yticks([0, 1], ['Non-UXO', 'UXO'])\n",
        "\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                plt.text(j, i, str(cm[i][j]), ha='center', va='center')\n",
        "\n",
        "        mlflow.log_figure(plt.gcf(), \"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "test_model()\n"
      ],
      "metadata": {
        "id": "Oyied1wMpXvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Sample predictions:***"
      ],
      "metadata": {
        "id": "_S5lfl0ipxp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(num_samples=3):\n",
        "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    model.eval()\n",
        "\n",
        "    samples = []\n",
        "    for i, (img, label) in enumerate(test_dataset):\n",
        "        if len(samples) >= num_samples:\n",
        "            break\n",
        "        samples.append((img, label))\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i, (img, label) in enumerate(samples):\n",
        "        with torch.no_grad():\n",
        "            output = model(img.unsqueeze(0).to(device))\n",
        "            pred = \"UXO\" if output > 0.5 else \"Non-UXO\"\n",
        "            confidence = output.item() if output > 0.5 else 1 - output.item()\n",
        "\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img.permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5)  # Unnormalize\n",
        "        plt.title(f\"True: {'UXO' if label == 1 else 'Non-UXO'}\\n\"\n",
        "                  f\"Pred: {pred} ({confidence:.2f})\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    mlflow.log_figure(plt.gcf(), \"sample_predictions.png\")\n",
        "    plt.show()\n",
        "\n",
        "show_predictions()"
      ],
      "metadata": {
        "id": "g_QhPbChp0H5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}